{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "openai-rvu": {
      "npm": "@ai-sdk/openai",
      "name": "OpenAI Direct",
      "options": {
        "baseURL": "https://litellm.external.rvu.cloud/v1",
        "apiKey": "{env:LITE_LLM_API_KEY}",
        "extraHeaders": {
          "litellm-drop-params": "true"
        }
      },
      "models": {
        "gpt-5": {
          "name": "GPT-5 Direct",
          "attachment": true,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 1.25,
            "output": 10.0,
            "cache_read": 0.31,
            "cache_write": 0
          },
          "limit": {
            "context": 400000,
            "output": 128000
          }
        },
        "gpt-5-mini": {
          "name": "GPT-5 Mini Direct",
          "attachment": true,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 1.25,
            "output": 10.0,
            "cache_read": 0.31,
            "cache_write": 0
          },
          "limit": {
            "context": 400000,
            "output": 128000
          }
        }
      }
    },
    "litellm": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "LiteLLM",
      "options": {
        "baseURL": "https://litellm.external.rvu.cloud/v1",
        "apiKey": "{env:LITE_LLM_API_KEY}",
        "extraHeaders": {
          "litellm-drop-params": "true"
        }
      },
      "models": {
        "eu.anthropic.claude-sonnet-4-20250514-v1:0": {
          "name": "Claude Sonnet 4",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 3.0,
            "output": 15.0,
            "cache_read": 0.3,
            "cache_write": 3.75
          },
          "limit": {
            "context": 200000,
            "output": 50000
          }
        },
        "eu.anthropic.claude-3-haiku-20240307-v1:0": {
          "name": "Claude 3 Haiku",
          "attachment": true,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 0.25,
            "output": 1.25,
            "cache_read": 0.08,
            "cache_write": 1.0
          },
          "limit": {
            "context": 200000,
            "output": 50000
          }
        },
        "o4-mini": {
          "name": "o4 Mini",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 1.1,
            "output": 4.4,
            "cache_read": 0.275,
            "cache_write": 0
          },
          "limit": {
            "context": 200000,
            "output": 50000
          }
        },
        "o3": {
          "name": "o3",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 2.0,
            "output": 8.0,
            "cache_read": 0.5,
            "cache_write": 0
          },
          "limit": {
            "context": 200000,
            "output": 50000
          }
        },
        "gpt-4.1": {
          "name": "GPT-4.1",
          "attachment": true,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 2.0,
            "output": 8.0,
            "cache_read": 0.5,
            "cache_write": 0
          },
          "limit": {
            "context": 1047576,
            "output": 16384
          }
        },
        "gpt-4.1-mini": {
          "name": "GPT-4.1 Mini",
          "attachment": true,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 0.4,
            "output": 1.6,
            "cache_read": 0.1,
            "cache_write": 0
          },
          "limit": {
            "context": 1047576,
            "output": 16384
          }
        },
        "gpt-4o": {
          "name": "GPT-4o",
          "attachment": true,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 2.5,
            "output": 10.0,
            "cache_read": 1.25,
            "cache_write": 0
          },
          "limit": {
            "context": 128000,
            "output": 8192
          }
        },
        "gemini-2.5-pro": {
          "name": "Gemini Pro 2.5",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 1.25,
            "output": 10.0,
            "cache_read": 1.25,
            "cache_write": 10.0
          },
          "limit": {
            "context": 1048576,
            "output": 65535
          }
        },
        "gemini-2.5-flash": {
          "name": "Gemini 2.5 Flash",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 0.3,
            "output": 2.5,
            "cache_read": 0.08,
            "cache_write": 2.5
          },
          "limit": {
            "context": 1048576,
            "output": 65535
          }
        },
        "gemini-2.5-flash-lite": {
          "name": "Gemini 2.5 Flash Lite",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 0.3,
            "output": 2.5,
            "cache_read": 0.08,
            "cache_write": 2.5
          },
          "limit": {
            "context": 1048576,
            "output": 65535
          }
        },
        "gemini-2.0-flash": {
          "name": "Gemini 2.0 Flash",
          "attachment": true,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 0.1,
            "output": 0.4,
            "cache_read": 0.03,
            "cache_write": 0.4
          },
          "limit": {
            "context": 1048576,
            "output": 8192
          }
        },
        "gemini-2.0-flash-lite": {
          "name": "Gemini 2.0 Flash Lite",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 0.1,
            "output": 0.4,
            "cache_read": 0.03,
            "cache_write": 0.4
          },
          "limit": {
            "context": 1048576,
            "output": 65535
          }
        },
        "gpt-5": {
          "name": "GPT-5",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 1.25,
            "output": 10.0,
            "cache_read": 0.31,
            "cache_write": 0
          },
          "limit": {
            "context": 400000,
            "output": 128000
          }
        },
        "gpt-5-chat-latest": {
          "name": "GPT-5 Chat Latest",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": false,
          "cost": {
            "input": 1.25,
            "output": 10.0,
            "cache_read": 0.31,
            "cache_write": 0
          },
          "limit": {
            "context": 400000,
            "output": 128000
          }
        },
        "gpt-5-mini": {
          "name": "GPT-5 Mini",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 1.25,
            "output": 10.0,
            "cache_read": 0.31,
            "cache_write": 0
          },
          "limit": {
            "context": 400000,
            "output": 128000
          }
        },
        "gpt-5-nano": {
          "name": "GPT-5 Nano",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 0.05,
            "output": 0.4,
            "cache_read": 0.01,
            "cache_write": 0
          },
          "limit": {
            "context": 400000,
            "output": 128000
          }
        },
        "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
          "name": "Claude 3.5 Sonnet",
          "attachment": true,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 3.0,
            "output": 15.0,
            "cache_read": 0.3,
            "cache_write": 3.75
          },
          "limit": {
            "context": 200000,
            "output": 4096
          }
        },
        "eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
          "name": "Claude 3.7 Sonnet",
          "attachment": true,
          "reasoning": true,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 3.0,
            "output": 15.0,
            "cache_read": 0.3,
            "cache_write": 3.75
          },
          "limit": {
            "context": 200000,
            "output": 8192
          }
        },
        "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
          "name": "Claude 3 Sonnet",
          "attachment": true,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 3.0,
            "output": 15.0,
            "cache_read": 0.3,
            "cache_write": 3.75
          },
          "limit": {
            "context": 200000,
            "output": 4096
          }
        },
        "eu.meta.llama3-2-1b-instruct-v1:0": {
          "name": "Llama 3.2 1B Instruct",
          "attachment": false,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 0.1,
            "output": 0.1,
            "cache_read": 0.025,
            "cache_write": 0
          },
          "limit": {
            "context": 128000,
            "output": 4096
          }
        },
        "eu.meta.llama3-2-3b-instruct-v1:0": {
          "name": "Llama 3.2 3B Instruct",
          "attachment": false,
          "reasoning": false,
          "temperature": true,
          "tool_call": true,
          "cost": {
            "input": 0.15,
            "output": 0.15,
            "cache_read": 0.04,
            "cache_write": 0
          },
          "limit": {
            "context": 128000,
            "output": 4096
          }
        },
        "mistral.mistral-7b-instruct-v0:2": {
          "name": "Mistral 7B Instruct",
          "attachment": false,
          "reasoning": false,
          "temperature": true,
          "tool_call": false,
          "cost": {
            "input": 0.15,
            "output": 0.2,
            "cache_read": 0.04,
            "cache_write": 0
          },
          "limit": {
            "context": 32000,
            "output": 8192
          }
        },
        "mistral.mistral-large-2402-v1:0": {
          "name": "Mistral Large 2402",
          "attachment": false,
          "reasoning": false,
          "temperature": true,
          "tool_call": false,
          "cost": {
            "input": 8.0,
            "output": 24.0,
            "cache_read": 2.0,
            "cache_write": 0
          },
          "limit": {
            "context": 32000,
            "output": 8192
          }
        },
        "mistral.mixtral-8x7b-instruct-v0:1": {
          "name": "Mixtral 8x7B Instruct",
          "attachment": false,
          "reasoning": false,
          "temperature": true,
          "tool_call": false,
          "cost": {
            "input": 0.45,
            "output": 0.7,
            "cache_read": 0.11,
            "cache_write": 0
          },
          "limit": {
            "context": 32000,
            "output": 8192
          }
        }
      }
    }
  },
  "model": "openai-rvu/gpt-5",
  "small_model": "litellm/eu.anthropic.claude-3-haiku-20240307-v1:0",
  "mcp": {
    "weather": {
      "type": "local",
      "command": ["opencode", "x", "@h1deya/mcp-server-weather"]
    },
    "grafana": {
      "type": "remote",
      "url": "https://mcp-grafana.tempcover.tech/sse"
    }
  }
}
